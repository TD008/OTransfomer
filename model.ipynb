{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNz8ew0YApNwO1kCtzLb5EK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TD008/OTransfomer/blob/main/model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "anZ0_fdWARKj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class AttHead(torch.nn.Module):\n",
        "    def __init__(self, dmodel, dk, dv, decoder=True):\n",
        "        super(AttHead, self).__init__()\n",
        "        self.dmodel = dmodel\n",
        "        self.dk = dk\n",
        "        self.dv = dv\n",
        "        self.decoder = decoder\n",
        "\n",
        "        self.key = torch.nn.Linear(dmodel, dk)\n",
        "        self.query = torch.nn.Linear(dmodel, dk)\n",
        "        self.value = torch.nn.Linear(dmodel, dv)\n",
        "        self.out = torch.nn.Linear(dv, dmodel)\n",
        "        self.smax = torch.nn.Softmax(dim = -1) # Will be applied along the dk dimension\n",
        "\n",
        "    def forward(self, x):\n",
        "    # want to input a tensor of (batch_size, block_size, dmodel) and output\n",
        "    # of dmodel/h ??\n",
        "\n",
        "        k = self.key(x)\n",
        "        q = self.query(x)\n",
        "        v = self.value(x)\n",
        "\n",
        "        affinities = q @ k.transpose(-2, -1)   # dot product of q and t packaged into a matrix mult.\n",
        "        affinities = affinities / (self.dk ** 0.5)  # Scale by sqrt(dk)\n",
        "\n",
        "        if self.decoder:\n",
        "            mask = torch.triu(torch.ones(x.size(1), x.size(1)), diagonal=1)\n",
        "            mask = mask.masked_fill(mask==1, float('-inf'))\n",
        "            affinities += mask\n",
        "\n",
        "        affinities = self.smax(affinities)   # Transform the affinities into weights summing to 1\n",
        "\n",
        "        output = affinities @ v\n",
        "        output = self.out(output)\n",
        "        return output\n"
      ],
      "metadata": {
        "id": "T0KeDfeMCQDm"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AttBlock(torch.nn.Module):\n",
        "    def __init__(self, num_heads, dmodel):\n",
        "        super(AttBlock, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.dmodel = dmodel\n",
        "        self.heads = [AttHead(dmodel, dmodel, dmodel) for i in range(num_heads)]\n",
        "\n",
        "    def __forward__(self, idx):\n",
        "        pass"
      ],
      "metadata": {
        "id": "wylP9e-fEjUT"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Quick sanity test\n",
        "batch_size = 2\n",
        "block_size = 4\n",
        "dmodel, dk, dv = 6, 6, 6\n",
        "\n",
        "data = torch.randn(batch_size, block_size, dmodel)\n",
        "print(\"data:\\n\", data)\n",
        "\n",
        "model = AttHead(dmodel, dk, dv)\n",
        "\n",
        "forward = model(data)\n",
        "print(\"forward:\\n\", forward)"
      ],
      "metadata": {
        "id": "MjTAP4s3YXSl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3622f385-64fa-4589-d844-a542f7efe10e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data:\n",
            " tensor([[[-0.0375, -0.7401, -0.5613,  0.6808,  0.6946, -1.4405],\n",
            "         [-0.3934,  0.1113,  0.0411, -0.0616,  1.6976, -0.9105],\n",
            "         [-0.8492,  1.0304, -0.3294, -0.3590, -1.4121, -0.0631],\n",
            "         [ 0.1757, -0.4288, -1.0191, -0.7912, -0.3052, -0.7022]],\n",
            "\n",
            "        [[ 0.3466, -0.9306,  0.3998, -0.7576, -0.6818, -0.2977],\n",
            "         [-0.2433, -0.5938,  0.5151, -0.1521,  2.3302, -0.7203],\n",
            "         [ 0.6507,  0.2706, -0.2490, -0.6644, -0.6329,  0.2481],\n",
            "         [ 0.9437, -0.7151,  0.3176, -0.6237,  0.3903,  0.2886]]])\n",
            "forward:\n",
            " tensor([[[-1.6528e-01,  5.2006e-01, -5.4918e-01,  7.3699e-01, -2.3925e-01,\n",
            "           3.2250e-01],\n",
            "         [-1.4137e-01,  3.8645e-01, -5.6850e-01,  5.6132e-01, -2.4060e-01,\n",
            "           2.0878e-01],\n",
            "         [-7.3153e-02,  3.1676e-01, -5.0752e-01,  4.1274e-01, -6.0772e-02,\n",
            "           1.2568e-01],\n",
            "         [-1.0167e-01,  4.2677e-01, -5.9716e-01,  4.6476e-01, -1.0579e-01,\n",
            "           1.5061e-01]],\n",
            "\n",
            "        [[ 7.7240e-02,  5.4421e-01, -4.9427e-01,  4.0210e-01, -2.0876e-01,\n",
            "           6.7322e-02],\n",
            "         [-5.5411e-04,  4.5132e-01, -5.4689e-01,  4.1622e-01, -3.0662e-01,\n",
            "           8.3185e-02],\n",
            "         [-1.1280e-02,  4.1349e-01, -5.3159e-01,  4.1101e-01, -2.3860e-01,\n",
            "           9.6792e-02],\n",
            "         [-1.2517e-02,  4.1105e-01, -5.2174e-01,  4.2820e-01, -2.3937e-01,\n",
            "           1.1468e-01]]], grad_fn=<ViewBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dx3FqgulVhTw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}